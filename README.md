# web-crawler

## How to start ?
### 1.Clone to local machine.
```sh
$ git clone https://github.com/amol3793/webcrawler.git <directory>
```

### 2.Installation
Create a new virtual environment and install the dependencies.
```sh
$ virtalenv <pathname> #create virtual environment
$ source <pathname>/bin/activate #activate virtual environment
$ pip install pip install -r requirements.txt #installing all dependencies
```
### 3. Running from console.

```sh
$ python webcrawler.py

Provide URL to crawl: https://google.com
Provide maximum depth to crawl: 4
